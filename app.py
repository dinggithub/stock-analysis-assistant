import streamlit as st
import openai
import json
from datetime import datetime
import pandas as pd
import logging
import time
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
log_dir = "logs"
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

log_file = os.path.join(log_dir, f"stock_analysis_{datetime.now().strftime('%Y%m%d')}.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('stock_analysis')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="Aè‚¡æ–°é—»åˆ†æåŠ©æ‰‹", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

if "is_first_message" not in st.session_state:
    st.session_state.is_first_message = True

if "history" not in st.session_state:
    st.session_state.history = []

if "should_stop" not in st.session_state:
    st.session_state.should_stop = False

# DeepSeek API é…ç½®
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
client = openai.OpenAI(
    api_key=DEEPSEEK_API_KEY,
    base_url="https://api.deepseek.com"
)

# å†…ç½®æç¤ºè¯
prompt_a = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆå’ŒAè‚¡å¸‚åœºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ–°é—»å¯¹Aè‚¡å¸‚åœºçš„å½±å“ã€‚

å½“ç”¨æˆ·æä¾›æ–°é—»å†…å®¹æ—¶ï¼Œè¯·ç»™å‡ºä»¥ä¸‹åˆ†æç»“è®ºï¼š

1. åˆ©å¥½ï¼š
- åˆ©å¥½åŸå› 
- å—ç›Šè¡Œä¸š
- ç›¸å…³Aè‚¡ä¸Šå¸‚å…¬å¸

2. åˆ©ç©ºï¼š
- åˆ©ç©ºåŸå› 
- å—æŸè¡Œä¸š

æ³¨æ„ï¼Œå¦‚æœæ–°é—»å¯¹Aè‚¡å½±å“ä¸æ˜æ˜¾ï¼Œè¯·ç›´æ¥è¯´æ˜"å½±å“æœ‰é™"ã€‚

æ–°é—»å†…å®¹ï¼š

{input}
"""

prompt_b = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é£é™©åˆ†æå¸ˆã€‚ç°åœ¨éœ€è¦ä½ åŸºäºåˆšæ‰çš„æ–°é—»å¯¹å‰æœŸåˆ†æçš„åˆ©å¥½è¡Œä¸šå’Œå…¬å¸è¿›è¡Œé£é™©æç¤ºã€‚

è¯·ä»è¡Œä¸šã€å…¬å¸åŠæ—¶é—´ï¼ˆçŸ­æœŸå’Œä¸­é•¿æœŸï¼‰ç»´åº¦è¿›è¡Œé£é™©åˆ†æï¼š

æ³¨æ„ï¼Œä¿æŒå®¢è§‚ä¸“ä¸šï¼Œé¿å…è¿‡åº¦æ‚²è§‚ï¼›é£é™©åˆ†æè¦æœ‰é’ˆå¯¹æ€§ï¼Œé¿å…æ³›æ³›è€Œè°ˆï¼›å¦‚æœè®¤ä¸ºæŸé¡¹é£é™©ç‰¹åˆ«é‡è¦ï¼Œè¯·ç”¨"âš ï¸"æ ‡æ³¨

å¦‚æœå‰æœŸåˆ†ææ˜¾ç¤º"å½±å“æœ‰é™"ï¼Œåˆ™ç›´æ¥å›å¤"æ— éœ€è¿›è¡Œé£é™©åˆ†æ"ã€‚
"""

# ç»“æ„åŒ–æ—¥å¿—è®°å½•å‡½æ•°
def log_generation(input_context: str, output: str, reasoning: str, model: str, duration: float, status: str, step: str):
    """è®°å½•ç”Ÿæˆè¿‡ç¨‹çš„æ—¥å¿—"""
    try:
        log_data = {
            "timestamp": datetime.now().isoformat(),
            "step": step,
            "input": input_context[:500] + "..." if len(input_context) > 500 else input_context,
            "output": output[:500] + "..." if len(output) > 500 else output,
            "reasoning": reasoning[:500] + "..." if reasoning and len(reasoning) > 500 else reasoning,
            "model_parameters": {
                "model": model,
            },
            "duration_seconds": duration,
            "status": status
        }
        logger.info(json.dumps(log_data, ensure_ascii=False))
    except Exception as e:
        logger.error(f"Failed to log generation: {str(e)}")

# å°†æ€ç»´é“¾è½¬æ¢ä¸ºå¼•ç”¨æ ¼å¼çš„å‡½æ•°
def format_reasoning_as_quote(reasoning_text):
    """å°†æ€ç»´é“¾è½¬æ¢ä¸ºMarkdownå¼•ç”¨æ ¼å¼"""
    if not reasoning_text:
        return ""
    lines = reasoning_text.split('\n')
    quoted_lines = [f"> {line}" for line in lines]
    return '\n'.join(quoted_lines)

# åˆ›å»ºå¸ƒå±€å‡½æ•°
def create_layout():
    msg_container = st.container()
    input_container = st.container()
    return msg_container, input_container

# æ˜¾ç¤ºæ¶ˆæ¯å‡½æ•°
def display_messages(container):
    with container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# é¦–æ¬¡æ¶ˆæ¯å¤„ç†ï¼ˆæ–°é—»åˆ†æï¼‰
def handle_first_message(user_input, msg_container):
    st.session_state.should_stop = False
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    with msg_container.chat_message("assistant"):
        st.markdown("### ğŸ“Š åˆ©å¥½åˆ†æ")
        reasoning1_placeholder = st.empty()
        impact_placeholder = st.empty()
        
        col1, col2 = st.columns([5,1])
        with col2:
            stop_button = st.button("åœæ­¢ç”Ÿæˆ", key="stop_button")
            if stop_button:
                st.session_state.should_stop = True
                return

        start_time_impact = time.time()
        formatted_prompt = prompt_a.format(input=user_input)
        first_reasoning = ""
        first_result = ""

        first_analysis_stream = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆå’ŒAè‚¡å¸‚åœºä¸“å®¶ã€‚"},
                {"role": "user", "content": formatted_prompt}
            ],
            stream=True
        )

        for chunk in first_analysis_stream:
            if st.session_state.should_stop:
                break
            if chunk.choices[0].delta.reasoning_content:
                content = chunk.choices[0].delta.reasoning_content
                first_reasoning += content
                reasoning1_placeholder.markdown(format_reasoning_as_quote(first_reasoning))
            elif chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                first_result += content
                impact_placeholder.markdown(first_result)

        impact_duration = time.time() - start_time_impact
        log_generation(
            input_context=formatted_prompt,
            output=first_result,
            reasoning=first_reasoning,
            model="deepseek-reasoner",
            duration=impact_duration,
            status="success",
            step="impact_analysis"
        )

        if not st.session_state.should_stop:
            st.markdown("### âš ï¸ é£é™©æç¤º")
            reasoning2_placeholder = st.empty()
            risk_placeholder = st.empty()
            start_time_risk = time.time()
            second_reasoning = ""
            second_result = ""

            second_analysis_stream = client.chat.completions.create(
                model="deepseek-reasoner",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é£é™©åˆ†æå¸ˆã€‚"},
                    {"role": "user", "content": formatted_prompt},
                    {"role": "assistant", "content": first_result},
                    {"role": "user", "content": prompt_b}
                ],
                stream=True
            )

            for chunk in second_analysis_stream:
                if st.session_state.should_stop:
                    break
                if chunk.choices[0].delta.reasoning_content:
                    content = chunk.choices[0].delta.reasoning_content
                    second_reasoning += content
                    reasoning2_placeholder.markdown(format_reasoning_as_quote(second_reasoning))
                elif chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    second_result += content
                    risk_placeholder.markdown(second_result)

            risk_duration = time.time() - start_time_risk
            log_generation(
                input_context=f"{formatted_prompt}\n\n{first_result}\n\n{prompt_b}",
                output=second_result,
                reasoning=second_reasoning,
                model="deepseek-reasoner",
                duration=risk_duration,
                status="success",
                step="risk_analysis"
            )

            complete_response = f"### ğŸ“Š åˆ©å¥½åˆ†æ\n\n{first_result}\n\n### âš ï¸ é£é™©æç¤º\n\n{second_result}"
            st.session_state.messages.append({"role": "assistant", "content": complete_response})

            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            st.session_state.history.append({
                "timestamp": timestamp,
                "news": user_input,
                "impact_analysis": first_result,
                "impact_reasoning": first_reasoning,
                "risk_analysis": second_result,
                "risk_reasoning": second_reasoning
            })

        st.session_state.is_first_message = False
        return first_result, second_result

# åç»­æ¶ˆæ¯å¤„ç†ï¼ˆå¸¸è§„å¯¹è¯ï¼‰
def handle_regular_message(user_input, msg_container):
    st.session_state.should_stop = False
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    messages = []
    for msg in st.session_state.messages[:-1]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": user_input})

    with msg_container.chat_message("assistant"):
        reasoning_placeholder = st.empty()
        message_placeholder = st.empty()
        
        col1, col2 = st.columns([5,1])
        with col2:
            stop_button = st.button("åœæ­¢ç”Ÿæˆ", key="stop_button")
            if stop_button:
                st.session_state.should_stop = True
                return

        start_time = time.time()
        reasoning = ""
        response = ""

        response_stream = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=messages,
            stream=True
        )

        for chunk in response_stream:
            if st.session_state.should_stop:
                break
            if chunk.choices[0].delta.reasoning_content:
                content = chunk.choices[0].delta.reasoning_content
                reasoning += content
                reasoning_placeholder.markdown(format_reasoning_as_quote(reasoning))
            elif chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                response += content
                message_placeholder.markdown(response)

        duration = time.time() - start_time
        log_generation(
            input_context=user_input,
            output=response,
            reasoning=reasoning,
            model="deepseek-reasoner",
            duration=duration,
            status="success",
            step="conversation"
        )

        st.session_state.messages.append({"role": "assistant", "content": response})
        return response

# æ˜¾ç¤ºå†å²è®°å½•
def show_history():
    st.subheader("å†å²åˆ†æè®°å½•")
    if not st.session_state.history:
        st.info("æš‚æ— å†å²è®°å½•")
        return

    for i, record in enumerate(reversed(st.session_state.history)):
        with st.expander(f"#{i+1} - {record['timestamp']}"):
            st.markdown("#### æ–°é—»å†…å®¹")
            try:
                news_text = record["news"][:200] + "..." if len(record["news"]) > 200 else record["news"]
                st.text(news_text)
            except Exception as e:
                st.text("(æ–°é—»å†…å®¹æ˜¾ç¤ºé”™è¯¯)")

            if st.button("æŸ¥çœ‹å®Œæ•´åˆ†æ", key=f"view_history_{i}"):
                st.markdown("#### ğŸ“Š è‚¡å¸‚åˆ†æ")
                st.markdown(format_reasoning_as_quote(record["impact_reasoning"]))
                st.markdown(record["impact_analysis"])
                st.markdown("#### âš ï¸ é£é™©æç¤º")
                st.markdown(format_reasoning_as_quote(record["risk_reasoning"]))
                st.markdown(record["risk_analysis"])

# æ·»åŠ CSSæ ·å¼
def inject_css():
    st.markdown("""
        <style>
        .stButton button {
            width: 100%;
        }
        .fixed-bottom {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            background: white;
            padding: 1rem;
            border-top: 1px solid #ddd;
        }
        .message-container {
            margin-bottom: 100px;
        }
        </style>
    """, unsafe_allow_html=True)

# ä¸»å‡½æ•°
def main():
    st.title("Aè‚¡æ–°é—»åˆ†æåŠ©æ‰‹")
    st.write("åŸºäº DeepSeek R1 æ¨¡å‹çš„æ–°é—»åˆ†æå·¥å…·ï¼Œå¸®åŠ©æ‚¨äº†è§£æ–°é—»å¯èƒ½å¯¹ A è‚¡å¸‚åœºçš„å½±å“ã€‚æ³¨æ„ï¼ŒR1æ¨¡å‹æœ‰è¾ƒå¼ºçš„å¹»è§‰ï¼Œå¯èƒ½ä¼šè¾“å‡ºä¸å‡†ç¡®çš„æ•°æ®ä¿¡æ¯ï¼Œè¯·æ ¸å®åä½¿ç”¨")

    msg_container, input_container = create_layout()
    
    tab1, tab2 = st.tabs(["å¯¹è¯", "å†å²è®°å½•"])
    
    with tab1:
        display_messages(msg_container)
        
        with input_container:
            col1, col2 = st.columns([6,1])
            with col1:
                user_input = st.text_input("è¾“å…¥æ–°é—»æˆ–æ‚¨çš„é—®é¢˜...", key="user_input")
            with col2:
                if st.button("å‘é€", key="send_button"):
                    if user_input:
                        try:
                            if st.session_state.is_first_message:
                                handle_first_message(user_input, msg_container)
                            else:
                                handle_regular_message(user_input, msg_container)
                            # æ·»åŠ ä»¥ä¸‹è¡Œæ¥æ¸…ç©ºè¾“å…¥æ¡†
                            st.session_state.user_input = ""
                            st.experimental_rerun()
                        except Exception as e:
                            st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
            
            if st.button("å¼€å§‹æ–°å¯¹è¯", key="new_conversation"):
                st.session_state.messages = []
                st.session_state.is_first_message = True
                st.experimental_rerun()
    
    with tab2:
        show_history()

if __name__ == "__main__":
    try:
        inject_css()
        main()
    except Exception as e:
        log_generation(
            input_context="åº”ç”¨å¯åŠ¨",
            output=str(e),
            reasoning="",
            model="deepseek-reasoner",
            duration=0.0,
            status="critical_error",
            step="app_startup"
        )
        st.error(f"åº”ç”¨è¿è¡Œé”™è¯¯: {str(e)}")